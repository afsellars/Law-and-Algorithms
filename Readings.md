# Law and Algorithms
## Spring 2024 Reading List
Thursdays, 2:10–4:10pm, BU Law Tower, Room 203

Please note that the readings in this course are highly likely to change over the course of the semester, though we try to avoid any changes to the readings less than a week before each class. 

For the full syllabus, [see here](Syllabus.pdf).

1. Modeling and Automation
  - [Intro to Modeling and Automation (Jan. 18)](#1-intro-to-modeling-and-automation-jan-18)
  - [Automation Bias vs. Non-Automation Bias (Jan. 25)](#2-automation-bias-vs-non-automation-bias-jan-25)
  - [Fairness in Automated Systems (Feb. 1)](#3-fairness-in-automated-systems-feb-1)
2. Embodying Algorithms in Software
  - [How Software is Constructed, Protected, and Examined (Feb. 8)](#4-how-software-is-constructed-protected-and-examined-feb-8)
  - [Putting Software On Trial (Feb. 15)](#5-putting-software-on-trial-feb-15)
  - [Creating an Ecosystem of Trustworthy Software (Feb. 22)](#6-creating-an-ecosystem-of-trustworthy-software-feb-22)
3. Layering in Secrecy
  - [Anonymization, Identification, and Formalized Notions of Privacy (Feb. 29)](#7-anonymization-identification-and-formalized-notions-of-privacy-feb-29)
  - [Bringing Formal Privacy to Public Administration (March 7)](#8-bringing-formal-privacy-to-public-administration-march-7)
  - [The Weaponization of Privacy (March 21)](#9-the-weaponization-of-privacy-march-21)
4. What Changes with Size?
  - [Data Access as a Measurement of Power (March 28)](#10-data-access-as-a-measurement-of-power-march-28)
  - [Harms in Machine Learning (April 4)](#11-harms-in-machine-learning-april-4)
  - [Correcting Harms in Machine Learning (April 11)](#12-correcting-harms-in-machine-learning-april-11)
5. Law & Algorithms
  - [Law and Algorithms (April 18)](#13-law-and-algorithms-april-18)

### Modeling and Automation

#### 1. Intro to Modeling and Automation (Jan. 18)

##### Intro to Algorithms
  
- Brandeis Hall Marshall, “Computational Thinking in Practice,” from _Data Conscience_ (2023) (circulated separately)
  - CDS students skim; Law students read from beginning, stopping at “Code Cloning” (pp. 87–97)

##### Intro to Law
- Andrew Sellars, [_A Practical Introduction to United States Law for Technologists_](SellarsPracticalIntro.pdf) (2023)
  - Law students skim; CDS students read Introduction and "The 'Common Law' System in the United States" (pp. 1–14), skim rest

##### The Social Construction of Data and Classification
- Sarah T. Roberts, “Your AI is a Human,” in _Your Computer is on Fire_ (2021) (circulated separately)
  - read from beginning to end of “The Case of Commercial Content Moderation…” and from “Humans and AI in Symbiosis and Conflict” to end (pp. 51–58, 64–67) 
- Anne L. Washington, “Source: Data are People, Too,” in _Ethical Data Science_ (2023) (circulated separately)
  - read from beginning of chapter through end of “Whose Control?” (pp. 29–34)
- Geoffrey C. Bowker & Susan Leigh Star, "Introduction: To Classify is Human," in _Sorting Things Out_ (2000) (circulated separately)
  - read beginning of “Introduction: To Classify is Human,” stopping at “Investigating Infrastructure” (pp. 1–8)

##### What is Gained and What is Lost as Law Becomes Computational
- Joel Reidenberg, [_Lex Informatica: The Formulation of Policy Rules through Technology_](https://ir.lawnet.fordham.edu/faculty_scholarship/42/), 76 Tex. L. Rev. 553 (1997)
  - read Part IV (pp. 576–86) only
- Ari Ezra Waldman, [_Power, Process, and Automated Decision-Making_](https://ir.lawnet.fordham.edu/cgi/viewcontent.cgi?article=5633&context=flr), 88 Fordham L. Rev. 613 (2019)
  - read read Section I (pp. 616–22) only

##### Who is Centered
- Catherine D’Ignazio and Lauren F. Klein, [“The Power Chapter,”](https://data-feminism.mitpress.mit.edu/pub/vi8obxh7/release/4) from _Data Feminism_ (2020)
  - read ["Data Science by Whom?"](https://data-feminism.mitpress.mit.edu/pub/vi8obxh7#data-science-by-whom) and ["Data Science for Whom?"](https://data-feminism.mitpress.mit.edu/pub/vi8obxh7#data-science-for-whom) only 

##### Optional Reading
- [_Guidance About How to Cover Artificial Intelligence_](https://www-apstylebook-com.ezproxy.bu.edu/boston-university-a7b40399-4032-42ea-9f9d-cb5ba7fe6946/ap_stylebook/artificial-intelligence-2), Associated Press Stylebook (2023)
- Dave Karpf, [_Why Can’t Our Tech Billionaires Learn Anything New?_](https://davekarpf.substack.com/p/why-cant-our-tech-billionaires-learn) (2023)
- Kristian Lum & Rumman Chowdhury, [_What is an “Algorithm?” It Depends Whom You Ask_](https://www.technologyreview.com/2021/02/26/1020007/what-is-an-algorithm/), MIT Tech. Review (Feb. 26, 2021)
- Tal Zarsky, [_The Trouble With Algorithmic Decisions_](https://www-jstor-org.ezproxy.bu.edu/stable/pdf/43671285.pdf?refreqid=excelsior%3A2a5553e4865160053cf0c7c22be43dc6), 41 Science, Technology, & Human Values 118 (2016)
- David Aurebach, [_The Stupidity of Computers_](https://www.nplusonemag.com/issue-13/essays/stupidity-of-computers/), n+1 (2012)
- Langdon Winner, [_Do Artifacts Have Politics?_](https://faculty.cc.gatech.edu/~beki/cs4001/Winner.pdf), 109 Daedalus 121 (1980)

#### 2. Automation Bias vs. Non-Automation Bias (Jan. 25)

##### Law's Trouble with Numbers
  - Edward K. Cheng, [_Fighting Legal Innumeracy_](http://www.greenbag.org/v17n3/v17n3_articles_cheng.pdf), 17 Green Bag 2d 271 (2014)
    - read sections I and II (pp. 271–76) only.

##### To Model or Not To Model: The Case of Sentencing Guidelines
  - Wendy Nelson Espeland & Berit Irene Vannebo, [_Accountability, Quantification, and Law_](https://www-annualreviews-org.ezproxy.bu.edu/doi/10.1146/annurev.lawsocsci.2.081805.105908), 3 Ann. Rev. L. & Social Sci. 21 (2007)
    - read “Federal Sentencing Guidelines” through the end of “Quantification in the Guidelines Approach” (pp. 25–33) 

##### "Automation Bias"
  - Danielle Keats Citron, [_Technological Due Process_](https://openscholarship.wustl.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1166&context=law_lawreview), 85 Wash. U. L. Rev. 1249 (2008) 
    - read part I(B) only (pp. 1267–77)

##### "Automation Bias" in the Other Direction
- Christopher Robertson, [_Robophobia in Medicine_](https://www.youtube.com/watch?v=jriC_BSnyz4&list=PLr-itzg5tymNefUaQWhcnBoAL0OZNqWSD&index=5) 
  - watch all
- S Mo Jones-Jang & Yong Jin Park, [_How do People React to AI Failure? Automation Bias, Algorithmic Aversion, and Perceived Controllability_](https://academic-oup-com.ezproxy.bu.edu/jcmc/article/28/1/zmac029/6827859?login=true&token=), 28 J. of Computer-Mediated Comm’n 1 (2022)
  - read “Literature Review” and “Discussion” (pp. 1–3, 6–7)

##### Where to Put the Humans
- Norman W. Spaulding, [“Is Human Judgment Necessary? Artificial Intelligence, Algorithmic Governance, and the Law,”](https://academic-oup-com.ezproxy.bu.edu/edited-volume/34287/chapter/290666019) in _The Oxford Handbook of Ethics of AI_ (2020)
  - read “Is Human Judgment Necessary?" (pp. 393–401)
- Rebecca Crootof, Margot Kaminski, & W. Nicholson Price II, [_Humans In the Loop_](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4066781), 76 Vand. L. Rev. 429 (2023) 
  - read section III (pp. 460–73)

#### 3. Fairness in Automated Systems (Feb. 1)

##### Defining Fairness
- Deborah Hellman, [_What is Discrimination, When is it Wrong, and Why?_](https://www.youtube.com/watch?v=qomsX8ZvvIY&t=226s), Plenary talk at the Conference for Fairness, Accountability, and Transparency (2018) 
  - watch the introduction to the talk (3:46–10:15)

##### Case Study: The COMPAS Algorithm
- Julia Angwin & Jeff Larson, [_Machine Bias_](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing), ProPublica (May 23, 2016)
  - read all
- [State v. Loomis](https://opencasebook.org/casebooks/2606-law-and-algorithms/resources/5.1-state-v-loomis/), 881 N.W.2d 749 (Wisc. 2016)
   - read excerpt

##### The Optimization Paradox
- Julia Angwin & Jeff Larson, [_Bias in Criminal Risk Scores Is Mathematically Inevitable, Researchers Say_](https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say), ProPublica (Dec. 30, 2016)
   - read all
- Karen Hao & Jonathan Stray, [_Can You Make AI Fairer than a Judge? Play Our Courtroom Algorithm Game_](https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/), MIT Technology Review (2019)
  - read all, and play with the interactive elements

##### Deeper Rethinking
- Ngozi Okidegbe, [_The Democratizing Potential of Algorithms?_](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3835370), 53 Conn. L. Rev. 739 (2022)
  - read part III only (pp. 767–77)
- Chelsea Barabas, [_Beyond Bias: Re-imagining the Terms of “Ethical AI” in Criminal Law_](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3377921), 12 Geo. J. L. & Mod. Crit. Race Persp. 83 (2020)
  - read Part VI (pp. 106–11) only

##### Optional Reading
- Sorelle A. Friedler, Carlos Scheidegger, & Suresh Venkatasubramanian, [_The (Im)possibility of Fairness: Different Value Systems Require Different Mechanisms For Fair Decision Making_](https://dl-acm-org.ezproxy.bu.edu/doi/abs/10.1145/3433949), 64 Comm. of the ACM (2021)
- Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan, [_Inherent Trade-Offs in the Fair Determination of Risk Scores_](https://drops.dagstuhl.de/storage/00lipics/lipics-vol067-itcs2017/LIPIcs.ITCS.2017.43/LIPIcs.ITCS.2017.43.pdf), 43 ITCS 1 (2017)
- Ran Canetti, Aloni Cohen, Nishanth Dikkala, Govind Ramnarayan, Sarah Scheffler, and Adam Smith, [_From Soft Classifiers to Hard Decisions: How Fair can we Be?_](https://arxiv.org/abs/1810.02003), FAT* (2019)
- Sandra G. Mayson, [_Bias In, Bias Out_](https://www.yalelawjournal.org/pdf/Mayson_p5g2tz2m.pdf), 128 Yale L.J. 2219 (2019)
- Deborah Hellman, [_Measuring Algorithmic Fairness_](https://heinonline-org.ezproxy.bu.edu/HOL/Page?handle=hein.journals/valr106&div=20&id=&page=&collection=journals), 106 Va. L. Rev. 811 (2020)
- Aziz Huq, [_Racial Equity in Algorithmic Criminal Justice_](https://scholarship.law.duke.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=3972&context=dlj), 68 Duke L.J. 1043 (2019)

### Embodying Algorithms in Software

#### 4. How Software is Constructed, Protected, and Examined (Feb. 8)

##### How Software is Built, How Software Breaks
- Carl E. Landwehr et al., [_A Taxonomy of Computer Program Security Flaws_](https://dl-acm-org.ezproxy.bu.edu/doi/pdf/10.1145/185403.185412), ACM Computing Surveys (1994)
  - read section 2.1.3 (pp. 219–21) only
- Ken Thompson, [_Reflections on Trusting Trust_](https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf), Turing Award Lecture (1984)
  - read the section “Moral” (p. 763) only
 
##### How Should We Interpret Software?
- James Grimmelmann, [_The Structure and Legal Protection of Computer Programs_](https://journalcrcl.org/crcl/article/view/19/13), J. of Cross-Disciplinary Reas. in Comp. L. (2023)
  - read all
 
##### How Software is Protected in Law
- Sonia Katyal, [_The Paradox of Source Code Secrecy_](https://scholarship.law.cornell.edu/clr/vol104/iss5/2/), 104 Cornell L. Rev. 1183 (2019)
  - read beginning of Part I through end of Part I(B) (pp. 1191–98) and Part I(D) (pp. 1207–10) 

##### What Follows from Trade Secrecy
- Rebecca Wexler, [_Life, Liberty, and Trade Secrets_](https://review.law.stanford.edu/wp-content/uploads/sites/3/2018/06/70-Stan.-L.-Rev.-1343.pdf), 70 Stan. L. Rev. 1343 (2018)
  - read from beginning of Part I to end of Part I(C) (pp. 1356–71)

#### 5. Putting Software On Trial (Feb. 15)

#### 6. Creating an Ecosystem of Trustworthy Software (Feb. 22)

### Layering in Secrecy

#### 7. Anonymization, Identification, and Formalized Notions of Privacy (Feb. 29)

#### 8. Bringing Formal Privacy to Public Administration (March 7)

#### 9. The Weaponization of Privacy (March 21)

### What Changes with Size?

#### 10. Data Access as a Measurement of Power (March 28)

#### 11. Harms in Machine Learning (April 4)

#### 12. Correcting Harms in Machine Learning (April 11)

### Law and Algorithms

#### 13. Law and Algorithms (April 18)
